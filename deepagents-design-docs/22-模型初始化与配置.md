# 22 - 模型初始化与配置详解

## 1. 概述

DeepAgents 的模型配置系统负责初始化和管理 LLM 实例。核心功能包括：
- 默认模型选择
- 字符串格式模型解析
- 子代理模型继承
- 模型配置驱动的中间件行为

## 2. 默认模型配置

### 2.1 get_default_model 函数

```python
from langchain_anthropic import ChatAnthropic


def get_default_model() -> ChatAnthropic:
    """获取 Deep Agents 的默认模型。
    
    默认使用 Claude Sonnet 4.5，这是一个平衡了性能和成本的模型选择。
    
    Returns:
        配置好的 ChatAnthropic 实例
    """
    return ChatAnthropic(
        model_name="claude-sonnet-4-5-20250929",
        max_tokens=20000,  # 扩展输出限制
    )
```

### 2.2 默认模型选择策略

| 模型 | 用途 | 特点 |
|------|------|------|
| claude-sonnet-4-5 | 默认主力 | 平衡性能与成本，20000 token输出 |
| claude-opus-4 | 复杂任务 | 最高质量，高成本 |
| claude-haiku | 简单任务 | 快速响应，低成本 |

## 3. 模型字符串解析

### 3.1 provider:model 格式

```python
from langchain.chat_models import init_chat_model

# create_deep_agent 中的模型解析逻辑
if model is None:
    model = get_default_model()
elif isinstance(model, str):
    # 支持 "provider:model" 格式
    model = init_chat_model(model)
```

### 3.2 支持的格式示例

```python
# OpenAI 模型
model = "openai:gpt-4o"
model = "openai:gpt-4o-mini"
model = "openai:gpt-5"

# Anthropic 模型
model = "anthropic:claude-sonnet-4-5-20250929"
model = "anthropic:claude-opus-4"

# Azure OpenAI
model = "azure:gpt-4"

# Google
model = "google:gemini-pro"
```

### 3.3 init_chat_model 解析流程

```
输入字符串: "openai:gpt-4o"
        ↓
解析 provider: openai
解析 model: gpt-4o
        ↓
加载对应 provider 的 ChatModel 类
        ↓
实例化并返回
```

## 4. create_deep_agent 中的模型处理

### 4.1 主代理模型初始化

```python
def create_deep_agent(
    model: str | BaseChatModel | None = None,
    ...
):
    # 1. 模型解析
    if model is None:
        model = get_default_model()
    elif isinstance(model, str):
        model = init_chat_model(model)
    
    # 2. 计算摘要默认值（基于模型配置）
    summarization_defaults = _compute_summarization_defaults(model)
    
    # 3. 模型用于所有子代理的默认配置
    ...
```

### 4.2 子代理模型继承

```python
# 处理用户提供的子代理
for spec in subagents or []:
    if "runnable" in spec:
        # CompiledSubAgent - 直接使用
        processed_subagents.append(spec)
    else:
        # SubAgent - 填充默认值
        subagent_model = spec.get("model", model)  # 继承主代理模型
        if isinstance(subagent_model, str):
            subagent_model = init_chat_model(subagent_model)
        
        # 为子代理计算独立的摘要默认值
        subagent_summarization_defaults = _compute_summarization_defaults(subagent_model)
        ...
```

### 4.3 通用子代理配置

```python
# 构建通用子代理（GP subagent）的默认中间件栈
gp_middleware: list[AgentMiddleware] = [
    TodoListMiddleware(),
    FilesystemMiddleware(backend=backend),
    SummarizationMiddleware(
        model=model,  # 使用主代理模型
        backend=backend,
        trigger=summarization_defaults["trigger"],
        keep=summarization_defaults["keep"],
        trim_tokens_to_summarize=None,
        truncate_args_settings=summarization_defaults["truncate_args_settings"],
    ),
    AnthropicPromptCachingMiddleware(unsupported_model_behavior="ignore"),
    PatchToolCallsMiddleware(),
]
```

## 5. 模型配置驱动的摘要策略

### 5.1 _compute_summarization_defaults 详解

```python
def _compute_summarization_defaults(model: BaseChatModel) -> SummarizationDefaults:
    """基于模型配置计算默认摘要策略。
    
    策略逻辑：
    - 如果模型有 max_input_tokens 配置：使用比例策略
    - 否则：使用固定值策略
    """
    has_profile = (
        model.profile is not None
        and isinstance(model.profile, dict)
        and "max_input_tokens" in model.profile
        and isinstance(model.profile["max_input_tokens"], int)
    )

    if has_profile:
        # 比例策略：基于上下文窗口百分比
        return {
            "trigger": ("fraction", 0.85),      # 85% 触发
            "keep": ("fraction", 0.10),         # 保留 10%
            "truncate_args_settings": {
                "trigger": ("fraction", 0.85),
                "keep": ("fraction", 0.10),
            },
        }
    
    # 固定值策略：保守的默认值
    return {
        "trigger": ("tokens", 170000),      # 17万 token
        "keep": ("messages", 6),            # 保留 6 条消息
        "truncate_args_settings": {
            "trigger": ("messages", 20),
            "keep": ("messages", 20),
        },
    }
```

### 5.2 不同模型的策略示例

| 模型 | max_input_tokens | 触发阈值 | 保留策略 |
|------|-----------------|---------|---------|
| claude-sonnet-4-5 | 200K | 170K tokens (85%) | 20K tokens (10%) |
| gpt-4o | 128K | 108K tokens (85%) | 12K tokens (10%) |
| gpt-4o-mini | 128K | 108K tokens (85%) | 12K tokens (10%) |
| 未知模型 | None | 170K tokens | 6 条消息 |

## 6. 中间件栈中的模型使用

### 6.1 主代理中间件栈

```python
deepagent_middleware: list[AgentMiddleware] = [
    TodoListMiddleware(),
    # ...
    SummarizationMiddleware(
        model=model,  # ← 主代理模型
        backend=backend,
        trigger=summarization_defaults["trigger"],
        keep=summarization_defaults["keep"],
        ...
    ),
    AnthropicPromptCachingMiddleware(...),
    PatchToolCallsMiddleware(),
]
```

### 6.2 子代理中间件栈

```python
# 每个子代理可以有自己的模型配置
subagent_middleware: list[AgentMiddleware] = [
    TodoListMiddleware(),
    FilesystemMiddleware(backend=backend),
    SummarizationMiddleware(
        model=subagent_model,  # ← 子代理特定模型
        backend=backend,
        trigger=subagent_summarization_defaults["trigger"],  # 基于子代理模型
        keep=subagent_summarization_defaults["keep"],
        ...
    ),
    ...
]
```

## 7. 模型配置完整流程

```
用户调用 create_deep_agent()
        ↓
    model = None / "openai:gpt-4o" / ChatModel实例
        ↓
┌─────────────────────────────────────────┐
│  模型解析阶段                            │
│  - None → get_default_model()           │
│  - str → init_chat_model()              │
│  - ChatModel → 直接使用                 │
└─────────────────────────────────────────┘
        ↓
┌─────────────────────────────────────────┐
│  策略计算阶段                            │
│  - _compute_summarization_defaults()    │
│  - 检查 model.profile                   │
│  - 选择比例策略或固定策略               │
└─────────────────────────────────────────┘
        ↓
┌─────────────────────────────────────────┐
│  子代理配置阶段                          │
│  - 继承或覆盖主代理模型                  │
│  - 为每个子代理计算摘要策略              │
│  - 构建中间件栈                          │
└─────────────────────────────────────────┘
        ↓
┌─────────────────────────────────────────┐
│  主代理构建阶段                          │
│  - 组装中间件栈                          │
│  - 配置 SummarizationMiddleware         │
│  - 调用 create_agent()                  │
└─────────────────────────────────────────┘
        ↓
返回 CompiledStateGraph
```

## 8. 使用示例

### 8.1 使用默认模型

```python
from deepagents import create_deep_agent

# 使用默认的 Claude Sonnet 4.5
agent = create_deep_agent()
```

### 8.2 使用字符串指定模型

```python
# 使用 OpenAI GPT-4o
agent = create_deep_agent(model="openai:gpt-4o")

# 使用 Claude Opus
agent = create_deep_agent(model="anthropic:claude-opus-4")
```

### 8.3 使用模型实例

```python
from langchain_anthropic import ChatAnthropic

# 自定义模型配置
model = ChatAnthropic(
    model_name="claude-sonnet-4-5-20250929",
    max_tokens=40000,
    temperature=0.7,
)

agent = create_deep_agent(model=model)
```

### 8.4 子代理使用不同模型

```python
agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-5",
    subagents=[
        {
            "name": "code_reviewer",
            "description": "Review code for quality",
            "prompt": "You are a code reviewer...",
            "model": "openai:gpt-4o-mini",  # 使用不同的模型
        },
        {
            "name": "architect",
            "description": "Design system architecture",
            "prompt": "You are a system architect...",
            "model": "anthropic:claude-opus-4",  # 使用更强的模型
        },
    ]
)
```

## 9. AnthropicPromptCachingMiddleware

### 9.1 配置与使用

```python
from langchain_anthropic.middleware import AnthropicPromptCachingMiddleware

# 在 create_deep_agent 中自动配置
deepagent_middleware = [
    ...
    AnthropicPromptCachingMiddleware(
        unsupported_model_behavior="ignore"  # 非Anthropic模型时静默
    ),
]
```

### 9.2 功能说明

- **提示缓存**：自动缓存系统提示和长内容
- **成本优化**：减少重复内容的token费用
- **模型兼容**：对非Anthropic模型静默处理

## 10. 关键设计决策

### 10.1 为什么使用比例策略？

```python
if has_profile:
    return {
        "trigger": ("fraction", 0.85),
        "keep": ("fraction", 0.10),
    }
```

**优点：**
1. **自适应**：自动适应不同上下文窗口
2. **一致性**：保持相同的触发比例
3. **未来证明**：支持新模型无需修改代码

### 10.2 为什么子代理独立计算策略？

```python
subagent_summarization_defaults = _compute_summarization_defaults(subagent_model)
```

**原因：**
- 子代理可能使用不同模型（如轻量级子代理用 GPT-4o-mini）
- 不同模型的上下文窗口不同
- 确保每个子代理的摘要策略最优

### 10.3 为什么支持模型字符串？

```python
model = init_chat_model("openai:gpt-4o")
```

**好处：**
- **简洁**：无需导入模型类
- **灵活**：运行时动态选择
- **配置友好**：可从配置文件读取

## 11. 总结

DeepAgents 的模型配置系统提供了：

1. **智能默认值**：基于模型配置自动选择最优策略
2. **灵活指定**：支持模型实例、字符串、None
3. **继承机制**：子代理默认继承主代理模型
4. **独立配置**：每个子代理可有自己的模型和策略
5. **成本优化**：集成 Anthropic 提示缓存

这种设计平衡了易用性和灵活性，让用户可以快速上手，同时支持复杂场景的深度定制。
